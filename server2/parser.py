# parser.py
import requests
import time
import pandas as pd
from database import db
from bs4 import BeautifulSoup
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class CompanyParser:
    def __init__(self, use_selenium=True):
        self.use_selenium = use_selenium
        self.driver = None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ requests session
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        })
        self.base_url = "https://www.gosuslugi.ru"
        self.search_url = "https://www.gosuslugi.ru/itorgs"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
        self._init_database()
        
        if self.use_selenium:
            self._init_selenium()
    
    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            db.init_connection()
            db.create_table()
            print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        
    def _init_selenium(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Selenium WebDriver"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            print("‚úÖ Selenium WebDriver –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Selenium: {e}")
            self.use_selenium = False

    def load_companies_from_excel(self, file_path, sheet_name='–ê–∫–∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–Ω—ã–µ –ò–¢-–∫–æ–º–ø–∞–Ω–∏–∏', limit=60):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ Excel —Ñ–∞–π–ª–∞"""
        try:
            print(f"üìñ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel —Ñ–∞–π–ª–∞: {file_path}")
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ limit —Å—Ç—Ä–æ–∫
            companies_data = df.head(limit)
            
            companies = []
            for index, row in companies_data.iterrows():
                company = {
                    'full_name': row.get('–ü–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', ''),
                    'short_name': row.get('–°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', ''),
                    'inn': str(row.get('–ò–ù–ù', '')).strip(),
                    'registration_date': row.get('–î–∞—Ç–∞ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ —É—á—ë—Ç', ''),
                    'revenue': row.get('–í—ã—Ä—É—á–∫–∞, —Ä—É–±.', ''),
                    'taxes_paid': row.get('–°—É–º–º–∞ —É–ø–ª–∞—á–µ–Ω–Ω—ã—Ö –Ω–∞–ª–æ–≥–æ–≤, —Ä—É–±.', ''),
                    'employees': row.get('–°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å', ''),
                    'usn_applied': row.get('–ü—Ä–∏–º–µ–Ω—è–µ—Ç –£–°–ù', ''),
                    'msp_inclusion_date': row.get('–î–∞—Ç–∞ –≤–∫–ª—é—á–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä –ú–°–ü', '')
                }
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ò–ù–ù –≤–∞–ª–∏–¥–Ω—ã–π (–Ω–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                if company['inn'] and company['inn'] != '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö' and len(company['inn']) >= 10:
                    companies.append(company)
                    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è: {company['short_name']} (–ò–ù–ù: {company['inn']})")
                else:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º –ò–ù–ù: {company['short_name']}")
            
            print(f"üìä –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(companies)}")
            return companies
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel: {e}")
            return []

    def _search_with_selenium(self, inn: str):
        """–ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Selenium"""
        if not self.driver:
            return None
            
        try:
            print(f"üõû –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞...")
            self.driver.get(self.search_url)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            time.sleep(3)
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ–ª–µ –≤–≤–æ–¥–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            print("üîç –ò—â–µ–º –ø–æ–ª–µ –≤–≤–æ–¥–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ...")
            
            selectors = [
                "input[type='text']",
                "input.search-input", 
                "input[aria-label*='–ø–µ—á–∞—Ç–∞—Ç—å']",
                "input[role='combobox']",
                ".search-input",
                "input"
            ]
            
            search_input = None
            for selector in selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            search_input = element
                            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –≤–≤–æ–¥–∞: {selector}")
                            break
                    if search_input:
                        break
                except:
                    continue
            
            if not search_input:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –≤–≤–æ–¥–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                return None
            
            # –í–≤–æ–¥–∏–º –ò–ù–ù
            print(f"‚å®Ô∏è –í–≤–æ–¥–∏–º –ò–ù–ù: {inn}")
            search_input.clear()
            search_input.send_keys(inn)
            
            time.sleep(1)
            
            # –ù–∞–∂–∏–º–∞–µ–º Enter
            print("‚Üµ –ù–∞–∂–∏–º–∞–µ–º Enter...")
            search_input.send_keys(Keys.ENTER)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            print("‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            time.sleep(5)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º URL - –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –∑–Ω–∞—á–∏—Ç —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
            current_url = self.driver.current_url
            print(f"üìÑ –¢–µ–∫—É—â–∏–π URL: {current_url}")
            
            # –ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_html = self.driver.page_source
            
            return {'html': page_html}
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Selenium: {e}")
            return None

    def _parse_search_result(self, html_content: str, inn: str):
        """–ü–∞—Ä—Å–∏—Ç HTML —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞...")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            text_blocks = []
            for element in soup.find_all(['div', 'p', 'h1', 'h2', 'h3', 'h4', 'h5', 'span']):
                text = element.get_text(strip=True)
                if text and len(text) > 5:
                    text_blocks.append(text)
            
            print(f"üìù –ù–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤: {len(text_blocks)}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_text = soup.get_text().lower()
            
            # –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è "–ù–ï –≤ —Ä–µ–µ—Å—Ç—Ä–µ"
            not_in_reestr_phrases = [
                '–Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ —Ä–µ–µ—Å—Ç—Ä',
                '–Ω–µ –Ω–∞–π–¥–µ–Ω–∞', 
                '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                '–∫–æ–º–ø–∞–Ω–∏—è —Å —Ç–∞–∫–∏–º–∏ —Ä–µ–∫–≤–∏–∑–∏—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
            ]
            
            # –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è "–í —Ä–µ–µ—Å—Ç—Ä–µ"  
            in_reestr_phrases = [
                '–≤—Ö–æ–¥–∏—Ç –≤ —Ä–µ–µ—Å—Ç—Ä',
                '–∞–∫–∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∞',
                '–∞–∫–∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–Ω—ã—Ö –∏—Ç-–∫–æ–º–ø–∞–Ω–∏–π'
            ]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–∑—ã –¥–ª—è "–ù–ï –≤ —Ä–µ–µ—Å—Ç—Ä–µ"
            for phrase in not_in_reestr_phrases:
                if phrase in page_text:
                    print(f"‚ùå –ù–∞–π–¥–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ '{phrase}' - –∫–æ–º–ø–∞–Ω–∏—è –ù–ï –≤ —Ä–µ–µ—Å—Ç—Ä–µ")
                    return {
                        'in_reestr': False,
                        'message': '–ö–æ–º–ø–∞–Ω–∏—è –Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ —Ä–µ–µ—Å—Ç—Ä –∞–∫–∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–Ω—ã—Ö –ò–¢-–∫–æ–º–ø–∞–Ω–∏–π',
                        'details': self._extract_company_details(soup, inn)
                    }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–∑—ã –¥–ª—è "–í —Ä–µ–µ—Å—Ç—Ä–µ"
            for phrase in in_reestr_phrases:
                if phrase in page_text:
                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ '{phrase}' - –∫–æ–º–ø–∞–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä–µ")
                    return {
                        'in_reestr': True,
                        'message': '–ö–æ–º–ø–∞–Ω–∏—è –≤—Ö–æ–¥–∏—Ç –≤ —Ä–µ–µ—Å—Ç—Ä –∞–∫–∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–Ω—ã—Ö –ò–¢-–∫–æ–º–ø–∞–Ω–∏–π',
                        'details': self._extract_company_details(soup, inn)
                    }
            
            # –ï—Å–ª–∏ —è–≤–Ω—ã—Ö —Ñ—Ä–∞–∑ –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏
            company_info = self._extract_company_details(soup, inn)
            if company_info and company_info.get('name') and company_info['name'] != f"–ö–æ–º–ø–∞–Ω–∏—è –ò–ù–ù {inn}":
                print("‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–∞–Ω–∏–∏ - –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –≤ —Ä–µ–µ—Å—Ç—Ä–µ")
                return {
                    'in_reestr': True,
                    'message': '–ö–æ–º–ø–∞–Ω–∏—è –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–µ—Å—Ç—Ä–µ',
                    'details': company_info
                }
            else:
                print("‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return {
                    'in_reestr': False,
                    'message': '–ö–æ–º–ø–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–µ—Å—Ç—Ä–µ',
                    'details': None
                }
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            return {
                'in_reestr': False,
                'message': f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}',
                'details': None
            }

    def _extract_company_details(self, soup: BeautifulSoup, inn: str):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            company_info = {
                'name': f"–ö–æ–º–ø–∞–Ω–∏—è –ò–ù–ù {inn}",
                'inn': inn,
                'ogrn': '',
                'address': '',
                'status': ''
            }
            
            # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            name_candidates = []
            
            # –ò—â–µ–º –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
            for tag in ['h1', 'h2', 'h3', 'h4', 'h5']:
                elements = soup.find_all(tag)
                for element in elements:
                    text = element.get_text(strip=True)
                    if text and len(text) > 5:
                        name_candidates.append(text)
            
            # –ò—â–µ–º –≤ div —Å –∫–ª–∞—Å—Å–∞–º–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ company, name, title
            for div in soup.find_all('div', class_=True):
                classes = ' '.join(div.get('class', []))
                if any(word in classes.lower() for word in ['company', 'name', 'title', 'organization']):
                    text = div.get_text(strip=True)
                    if text and len(text) > 5:
                        name_candidates.append(text)
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (—Å–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ, –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—â–µ–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤)
            best_name = f"–ö–æ–º–ø–∞–Ω–∏—è –ò–ù–ù {inn}"
            for candidate in name_candidates:
                if (len(candidate) > len(best_name) and 
                    not any(word in candidate.lower() for word in ['—Ä–µ–µ—Å—Ç—Ä', '–∞–∫–∫—Ä–µ–¥–∏—Ç', '–ø–æ–∏—Å–∫', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç', '–∫–∞—Ç–∞–ª–æ–≥', '–≤–æ–π—Ç–∏', '–≥–æ—Å—É—Å–ª—É–≥–∏', '–∏—Ç-–∫–æ–º–ø–∞–Ω–∏'])):
                    best_name = candidate
            
            company_info['name'] = best_name
            
            if best_name != f"–ö–æ–º–ø–∞–Ω–∏—è –ò–ù–ù {inn}":
                print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏: {best_name}")
            
            # –ò—â–µ–º –û–ì–†–ù
            all_text = soup.get_text()
            ogrn_patterns = [
                r'–û–ì–†–ù[:\s]*([0-9]{13,15})',
                r'–û–ì–†–ù–ò–ü[:\s]*([0-9]{13,15})',
                r'([0-9]{13,15}).*–û–ì–†–ù'
            ]
            
            for pattern in ogrn_patterns:
                ogrn_match = re.search(pattern, all_text, re.IGNORECASE)
                if ogrn_match:
                    company_info['ogrn'] = ogrn_match.group(1)
                    print(f"‚úÖ –û–ì–†–ù: {company_info['ogrn']}")
                    break
            
            return company_info
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –∫–æ–º–ø–∞–Ω–∏–∏: {e}")
            return {
                'name': f"–ö–æ–º–ø–∞–Ω–∏—è –ò–ù–ù {inn}",
                'inn': inn,
                'ogrn': '',
                'address': '',
                'status': ''
            }

    def check_company_by_inn(self, inn: str, company_data: dict = None):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–º–ø–∞–Ω–∏—é –ø–æ –ò–ù–ù"""
        try:
            print(f"\nüîç –ü–†–û–í–ï–†–ö–ê –ö–û–ú–ü–ê–ù–ò–ò –° –ò–ù–ù: {inn}")
            
            if company_data:
                print(f"üìã –ö–æ–º–ø–∞–Ω–∏—è: {company_data.get('short_name', 'N/A')}")
            
            search_result = self._search_with_selenium(inn)
            
            if not search_result:
                return {
                    "inn": inn,
                    "exists": False,
                    "in_reestr": False,
                    "details": None,
                    "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫",
                    "source": "selenium",
                    "company_data": company_data
                }
            
            if 'html' in search_result:
                parsed_result = self._parse_search_result(search_result['html'], inn)
                
                company_info = {
                    "name": parsed_result['details']['name'] if parsed_result['details'] else f"–ö–æ–º–ø–∞–Ω–∏—è –ò–ù–ù {inn}",
                    "inn": inn,
                    "ogrn": parsed_result['details']['ogrn'] if parsed_result['details'] else '',
                    "reestr": parsed_result['in_reestr']
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                try:
                    db_result = db.insert_company(company_info)
                    if db_result:
                        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
                    else:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
                
                return {
                    "inn": inn,
                    "exists": parsed_result['in_reestr'],
                    "in_reestr": parsed_result['in_reestr'],
                    "details": company_info,
                    "message": parsed_result['message'],
                    "source": "selenium",
                    "company_data": company_data
                }
            
        except Exception as e:
            print(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–æ–º–ø–∞–Ω–∏–∏: {e}")
            return {
                "inn": inn,
                "exists": False,
                "in_reestr": False,
                "details": None,
                "error": str(e),
                "source": "selenium",
                "company_data": company_data
            }

    def check_multiple_companies(self, companies_list: list):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–Ω–∏–π —Å –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏"""
        results = []
        total = len(companies_list)
        
        for i, company in enumerate(companies_list, 1):
            print(f"\nüìä [{i}/{total}] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏...")
            
            result = self.check_company_by_inn(company['inn'], company)
            results.append(result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.save_results_to_csv(results, f"intermediate_results_{i}.csv")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π)
            if i < total:
                delay = 5  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                print(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ {delay} —Å–µ–∫—É–Ω–¥...")
                time.sleep(delay)
        
        return results

    def save_results_to_csv(self, results, filename="parsing_results.csv"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV —Ñ–∞–π–ª"""
        try:
            data_to_save = []
            for result in results:
                row = {
                    '–ò–ù–ù': result['inn'],
                    '–°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': result.get('company_data', {}).get('short_name', ''),
                    '–ü–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': result.get('company_data', {}).get('full_name', ''),
                    '–í —Ä–µ–µ—Å—Ç—Ä–µ': '–î–∞' if result['in_reestr'] else '–ù–µ—Ç',
                    '–°—Ç–∞—Ç—É—Å –ø—Ä–æ–≤–µ—Ä–∫–∏': result.get('message', ''),
                    '–ù–∞–π–¥–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': result.get('details', {}).get('name', ''),
                    '–û–ì–†–ù': result.get('details', {}).get('ogrn', ''),
                    '–í—ã—Ä—É—á–∫–∞': result.get('company_data', {}).get('revenue', ''),
                    '–ù–∞–ª–æ–≥–∏': result.get('company_data', {}).get('taxes_paid', ''),
                    '–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏': result.get('company_data', {}).get('employees', ''),
                    '–ü—Ä–∏–º–µ–Ω—è–µ—Ç –£–°–ù': result.get('company_data', {}).get('usn_applied', ''),
                    '–û—à–∏–±–∫–∞': result.get('error', '')
                }
                data_to_save.append(row)
            
            df = pd.DataFrame(data_to_save)
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV: {e}")

    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é –∏ –¥—Ä–∞–π–≤–µ—Ä"""
        if self.session:
            self.session.close()
        if self.driver:
            try:
                self.driver.quit()
                print("‚úÖ Selenium –∑–∞–∫—Ä—ã—Ç")
            except:
                pass

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
parser = CompanyParser(use_selenium=True)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–µ—Ä–≤—ã—Ö 60 –∫–æ–º–ø–∞–Ω–∏–π
if __name__ == '__main__':
    print("üöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ò–ù–ì–ê –ü–ï–†–í–´–• 60 –ö–û–ú–ü–ê–ù–ò–ô –ò–ó EXCEL")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ Excel
        file_path = "Dop_materialy_Razrabotka_analiticheskoj_sistemy_Akkreditovannye (1).xlsx"
        companies = parser.load_companies_from_excel(file_path, limit=60)
        
        if companies:
            print(f"\nüéØ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É {len(companies)} –∫–æ–º–ø–∞–Ω–∏–π...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∫–æ–º–ø–∞–Ω–∏–∏
            results = parser.check_multiple_companies(companies)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            parser.save_results_to_csv(results, "final_parsing_results.csv")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            in_reestr_count = sum(1 for r in results if r['in_reestr'])
            print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            print(f"   –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {len(results)}")
            print(f"   –í —Ä–µ–µ—Å—Ç—Ä–µ: {in_reestr_count}")
            print(f"   –ù–µ –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {len(results) - in_reestr_count}")
            
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ Excel —Ñ–∞–π–ª–∞")
            
    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        print(traceback.format_exc())
    finally:
        parser.close()